{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn.utils import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csgraph\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data('cora')\n",
    "features = features.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_cat(X):\n",
    "    '''\n",
    "    shape of X = (n_samples, n_classes)\n",
    "    '''\n",
    "    return np.apply_along_axis(arr=X, axis=1, func1d=lambda x: np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(decision_function_shape='ovr', C=1, kernel='linear')\n",
    "\n",
    "def try_model(features, train_mask, y_train, model):\n",
    "    model.fit(features[train_mask, :], one_hot_to_cat(y_train[train_mask]))\n",
    "    print model.score(features[test_mask], one_hot_to_cat(y_test[test_mask,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_to_graph(adj):\n",
    "    A = coo_matrix(adj)    \n",
    "    N, _ = adj.shape\n",
    "    edges = zip(A.row, A.col)\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(range(N))\n",
    "    graph.add_edges_from(edges)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = adj_to_graph(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train by stacking features of neighbours\n",
    "feature_extra = np.zeros(features.shape)\n",
    "\n",
    "for n in graph.nodes():\n",
    "    feature_neighbors = np.mean([features[m] for m in graph.neighbors(n)], axis=0)\n",
    "    \n",
    "    feature_neighbors_2 = []\n",
    "    for m in graph.neighbors(n):\n",
    "        feature_neighbors_2.append(np.mean([features[p] for p in graph.neighbors(m)], axis=0))\n",
    "    feature_neighbors_2 = np.mean(feature_neighbors_2, axis=0)\n",
    "    \n",
    "    feature_extra[n] = 0 * features[n] + 3 * feature_neighbors + 5 * feature_neighbors_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802\n"
     ]
    }
   ],
   "source": [
    "try_model(feature_extra, train_mask, y_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_features(features, n, params):\n",
    "    padding = params.get('padding', 10)\n",
    "    n_features = len(features[0])\n",
    "    \n",
    "    feature = []\n",
    "    feature.append(features[n])\n",
    "    feature = feature + [features[m] for m in graph.neighbors(n)]    \n",
    "\n",
    "    if len(feature) >= padding:\n",
    "        feature = feature[:padding]\n",
    "    else:\n",
    "        feature = feature + [np.zeros(n_features) for _ in range(padding - len(feature))]\n",
    "    \n",
    "    \n",
    "    assert len(feature) == padding\n",
    "    return np.array(feature)\n",
    "    \n",
    "def apply_feature_transformation(features, func, params={}):\n",
    "    new_features = []\n",
    "    N = len(features)\n",
    "    \n",
    "    for n in range(N):\n",
    "        new_features.append(func(features, n, params))\n",
    "    \n",
    "    return np.array(new_features)\n",
    "\n",
    "features_neigh = apply_feature_transformation(features, concat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10, 1433)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 14330)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2048)              29349888  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 32,239,111\n",
      "Trainable params: 32,239,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 140 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 5s - loss: 2.0012 - acc: 0.2000 - val_loss: 1.9796 - val_acc: 0.1910\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 5s - loss: 1.1922 - acc: 0.6214 - val_loss: 1.3858 - val_acc: 0.5600\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 5s - loss: 0.2061 - acc: 0.9786 - val_loss: 1.2366 - val_acc: 0.5550\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 5s - loss: 0.0171 - acc: 1.0000 - val_loss: 1.5493 - val_acc: 0.5830\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 6s - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3782 - val_acc: 0.6640\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 5s - loss: 1.2450e-04 - acc: 1.0000 - val_loss: 1.3392 - val_acc: 0.6950\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 5s - loss: 1.0514e-04 - acc: 1.0000 - val_loss: 1.3399 - val_acc: 0.7040\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 5s - loss: 4.0028e-05 - acc: 1.0000 - val_loss: 1.3430 - val_acc: 0.7080\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 5s - loss: 4.3124e-05 - acc: 1.0000 - val_loss: 1.3426 - val_acc: 0.7120\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 6s - loss: 6.5469e-05 - acc: 1.0000 - val_loss: 1.3406 - val_acc: 0.7110\n",
      "1000/1000 [==============================] - 3s     \n",
      "[1.3406349155306816, 0.71100000083446502]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization, Embedding\n",
    "from keras import regularizers, losses\n",
    "\n",
    "n_epoch = 10\n",
    "batch_size= 20\n",
    "\n",
    "def get_model(n_features, n_classes):\n",
    "    # Model parameters\n",
    "    input_shape = n_features\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    flat = Flatten()(inp)\n",
    "    hidden_1 = Dense(2048, activation='relu')(flat)\n",
    "    dropout_1 = Dropout(0.2)(hidden_1)\n",
    "    \n",
    "    hidden_2 = Dense(1024, activation='relu')(dropout_1)\n",
    "    dropout_2 = Dropout(0.4)(hidden_2)\n",
    "    \n",
    "    hidden_3 = Dense(512, activation='relu')(dropout_2)\n",
    "    hidden_4 = Dense(512, activation='tanh')(hidden_3)\n",
    "    dropout_3 = Dropout(0.2)(hidden_4)\n",
    "    \n",
    "    out = Dense(n_classes, activation='softmax')(dropout_3)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "n_features = len(features[0])\n",
    "n_classes = len(y_train[0])\n",
    "\n",
    "features_neigh = apply_feature_transformation(features, concat_features, params={'padding': 10})\n",
    "\n",
    "model = get_model((10, n_features), n_classes)\n",
    "\n",
    "def train_score_model(model, features, y_train, y_test):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(features[train_mask, :], y_train[train_mask, :], batch_size=batch_size, epochs=n_epoch,\n",
    "          verbose=1, validation_data=(features[test_mask], y_test[test_mask]))\n",
    "    print model.evaluate(features[test_mask], y_test[test_mask], batch_size=batch_size)\n",
    "    \n",
    "train_score_model(model, features_neigh, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_pow = adj.copy()\n",
    "\n",
    "for _ in range(4):\n",
    "    adj_pow = adj.dot(adj_pow)\n",
    "adj_pow = adj_pow / adj_pow.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = np.array([len(graph.neighbors(n)) for n in graph.nodes()])\n",
    "\n",
    "y_cat_train = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
